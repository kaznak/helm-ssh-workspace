apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ssh-workspace.fullname" . }}
  labels:
    {{- include "ssh-workspace.labels" . | nindent 4 }}
spec:
  # Fixed replicas [J8R2-DEPLOY]
  replicas: {{ .Values.replicaCount }}
  # Update strategy [Y3S2-DOWN]
  strategy:
    {{- toYaml .Values.updateStrategy | nindent 4 }}
  selector:
    matchLabels:
      {{- include "ssh-workspace.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "ssh-workspace.labels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "ssh-workspace.serviceAccountName" . }}
      # Pod security context
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      # Init container for SSH key setup
      initContainers:
        - name: ssh-key-setup
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          # Run as root for user/group creation and file operations
          securityContext:
            runAsUser: 0
          command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "Setting up SSH environment..."
              
              # Create user and group if they don't exist
              if ! getent group {{ .Values.user.gid }} >/dev/null; then
                groupadd -g {{ .Values.user.gid }} {{ .Values.user.name }}
              fi
              if ! id {{ .Values.user.name }} >/dev/null 2>&1; then
                useradd -u {{ .Values.user.uid }} -g {{ .Values.user.gid }} -d /home/{{ .Values.user.name }} -s /bin/bash {{ .Values.user.name }}
              fi
              
              # Create SSH directories
              mkdir -p /home/{{ .Values.user.name }}/.ssh
              mkdir -p /home/{{ .Values.user.name }}/.ssh/dropbear
              
              # Copy SSH host keys from mounted secrets (with default permissions)
              if [ -f /mnt/ssh-host-keys/rsa_host_key ]; then
                cp /mnt/ssh-host-keys/rsa_host_key /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_rsa_host_key
                chmod 600 /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_rsa_host_key
              fi
              if [ -f /mnt/ssh-host-keys/ed25519_host_key ]; then
                cp /mnt/ssh-host-keys/ed25519_host_key /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_ed25519_host_key
                chmod 600 /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_ed25519_host_key
              fi
              
              # Copy SSH public keys (authorized_keys) from mounted secrets
              if [ -f /mnt/ssh-public-keys/authorized_keys ]; then
                cp /mnt/ssh-public-keys/authorized_keys /home/{{ .Values.user.name }}/.ssh/authorized_keys
                chmod 600 /home/{{ .Values.user.name }}/.ssh/authorized_keys
              fi
              
              # Copy SSH private keys if they exist
              {{- if or .Values.ssh.privateKeys.secretName .Values.ssh.privateKeys.keys }}
              if [ -d /mnt/ssh-private-keys ]; then
                for key_file in /mnt/ssh-private-keys/*; do
                  if [ -f "$key_file" ]; then
                    cp "$key_file" /home/{{ .Values.user.name }}/.ssh/
                    chmod 600 /home/{{ .Values.user.name }}/.ssh/$(basename "$key_file")
                  fi
                done
              fi
              {{- end }}
              
              # Set proper ownership
              chown -R {{ .Values.user.uid }}:{{ .Values.user.gid }} /home/{{ .Values.user.name }}/.ssh
              
              echo "SSH environment setup completed"
          volumeMounts:
            # Home directory mount
            - name: home
              mountPath: /home/{{ .Values.user.name }}
            # SSH host keys mount (read from default location)
            - name: ssh-host-keys
              mountPath: /mnt/ssh-host-keys
              readOnly: true
            # SSH public keys mount (read from default location)
            - name: ssh-public-keys
              mountPath: /mnt/ssh-public-keys
              readOnly: true
            # SSH private keys mount (if configured)
            {{- if or .Values.ssh.privateKeys.secretName .Values.ssh.privateKeys.keys }}
            - name: ssh-private-keys
              mountPath: /mnt/ssh-private-keys
              readOnly: true
            {{- end }}
      containers:
        - name: {{ .Chart.Name }}
          # Container security context [X2K7-RESTRICT]
          securityContext:
            runAsUser: {{ .Values.user.uid }}
            runAsGroup: {{ .Values.user.gid }}
            runAsNonRoot: true
            {{- if not (empty .Values.securityContext) }}
            {{- toYaml .Values.securityContext | nindent 12 }}
            {{- end }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          # Environment variables for user configuration [Y4F1-USER]
          env:
            - name: SSH_USERNAME
              value: {{ .Values.user.name | quote }}
            - name: SSH_UID
              value: {{ .Values.user.uid | quote }}
            - name: SSH_GID
              value: {{ .Values.user.gid | quote }}
          # Override entrypoint to run dropbear directly
          command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "Starting SSH workspace as user {{ .Values.user.name }} ({{ .Values.user.uid }}:{{ .Values.user.gid }})"
              
              # Start dropbear as the specified user
              echo "Starting Dropbear SSH server..."
              exec dropbear -F -p {{ .Values.ssh.port }} -r /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_rsa_host_key -r /home/{{ .Values.user.name }}/.ssh/dropbear/dropbear_ed25519_host_key
          ports:
            - name: ssh
              containerPort: {{ .Values.ssh.port }}
              protocol: TCP
          # Health checks [Q1P4-HEALTH]
          {{- if .Values.healthCheck.livenessProbe.enabled }}
          livenessProbe:
            tcpSocket:
              port: ssh
            initialDelaySeconds: {{ .Values.healthCheck.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.livenessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.healthCheck.livenessProbe.failureThreshold }}
            successThreshold: {{ .Values.healthCheck.livenessProbe.successThreshold }}
          {{- end }}
          {{- if .Values.healthCheck.readinessProbe.enabled }}
          readinessProbe:
            exec:
              command:
                - /opt/ssh-workspace/bin/health-check.sh
            initialDelaySeconds: {{ .Values.healthCheck.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.readinessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.healthCheck.readinessProbe.failureThreshold }}
            successThreshold: {{ .Values.healthCheck.readinessProbe.successThreshold }}
          {{- end }}
          # Resource limits [J1X6-LIMIT]
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          # Volume mounts
          volumeMounts:
            # Home directory mount [V5Q3-HOME]
            - name: home
              mountPath: /home/{{ .Values.user.name }}
              {{- if and (eq .Values.homeDirectory.type "persistentVolume") .Values.homeDirectory.persistentVolume.subPath }}
              subPath: {{ .Values.homeDirectory.persistentVolume.subPath }}
              {{- end }}
      volumes:
        # Home directory volume [V5Q3-HOME]
        - name: home
          {{- if eq .Values.homeDirectory.type "persistentVolume" }}
          persistentVolumeClaim:
            claimName: {{ include "ssh-workspace.fullname" . }}-home
          {{- else }}
          emptyDir:
            {{- if .Values.homeDirectory.emptyDir.sizeLimit }}
            sizeLimit: {{ .Values.homeDirectory.emptyDir.sizeLimit }}
            {{- end }}
          {{- end }}
        # SSH host keys volume [W5X2-SECRET]
        - name: ssh-host-keys
          secret:
            secretName: {{ .Values.ssh.hostKeys.secretName | default (printf "%s-ssh-hostkeys" (include "ssh-workspace.fullname" .)) }}
        # SSH public keys volume [P5Q8-PUBKEY]
        - name: ssh-public-keys
          secret:
            secretName: {{ .Values.ssh.publicKeys.secretName | default (printf "%s-ssh-pubkeys" (include "ssh-workspace.fullname" .)) }}
        # SSH private keys volume [R2L7-PRIVKEY]
        {{- if or .Values.ssh.privateKeys.secretName .Values.ssh.privateKeys.keys }}
        - name: ssh-private-keys
          secret:
            secretName: {{ .Values.ssh.privateKeys.secretName | default (printf "%s-ssh-privkeys" (include "ssh-workspace.fullname" .)) }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}